# Customer Personality Analysis  
![Project Status](https://img.shields.io/badge/Project%20Status-ongoing-orange)

## ğŸ“Œ Overview  
Customer Personality Analysis helps businesses understand customer behavior, segment users, and provide personalized recommendations. This project leverages **Machine Learning Operations (MLOps)** to streamline model training, deployment, and monitoring.

## âš  Important Note  
- **Python Version:** Please ensure you are using **Python 3.12** to maintain compatibility with the project's dependencies and requirements.

---

## ğŸ“‚ Project Navigation  
ğŸ“ [**Notebooks**](notebooks/) | ğŸ“ [**Pipelines**](src/pipeline/) | ğŸ“ [**Airflow DAGs**](airflow/dags/) | ğŸ“ [**Docs**](docs/) | ğŸ“ [**Deployment**](deployment/)

---
<h2 align="">Tools and Technologies Used</h2>
<p align="center">
    <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" alt="Scikit-learn" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://upload.wikimedia.org/wikipedia/commons/8/84/Matplotlib_icon.svg" alt="Matplotlib" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png" alt="AWS" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://upload.wikimedia.org/wikipedia/commons/4/4e/Docker_%28container_engine%29_logo.svg" alt="Docker" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png" alt="GitHub" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://seaborn.pydata.org/_images/logo-wide-lightbg.svg" alt="Seaborn" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://upload.wikimedia.org/wikipedia/commons/e/ed/Pandas_logo.svg" alt="Pandas" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://upload.wikimedia.org/wikipedia/commons/3/31/NumPy_logo_2020.svg" alt="NumPy" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://streamlit.io/images/brand/streamlit-mark-color.png" alt="Streamlit" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg" alt="Python" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://www.mongodb.com/assets/images/global/favicon.ico" alt="MongoDB" height="60">&nbsp;&nbsp;&nbsp;
    <img src="https://airflow.apache.org/docs/apache-airflow/stable/_images/apache-airflow-icon.png" alt="Apache Airflow" height="60">
</p>

Customer-Personality-Analysis/
## ğŸ’ï¸ Project Structure
```
Restaurant-Rating-Prediction/
â”‚
â”œâ”€â”€ .dockerignore                     # ğŸš« Ignore files for Docker
â”œâ”€â”€ .env                              # ğŸ”‘ Environment variables
â”œâ”€â”€ .gitignore                        # ğŸš« Ignore files for Git
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ main.yaml                 # âš™ï¸ GitHub Actions CI/CD pipeline
â”‚
â”œâ”€â”€ airflow/                          # ğŸ’¨ Apache Airflow DAGs
â”‚   â””â”€â”€ dags/                         # ğŸ“… Workflow DAGs
â”‚       â”œâ”€â”€ clustering_pipeline.py# ğŸ” Airflow DAG for clustering
â”‚       â””â”€â”€ training_pipeline.py      # ğŸ¯ Airflow DAG for model training
â”‚
â”œâ”€â”€ artifact/                        # ğŸ‚ Contains all intermediate and final outputs
â”œâ”€â”€ clustered_files/                  # ğŸ“‚ Clustered processed files
â”œâ”€â”€ data_dump.py                      # ğŸ›‹ï¸ Dumps data into MongoDB Atlas
â”œâ”€â”€ docker-compose.yml                # ğŸ”§ Docker Compose for multi-container setup
â”œâ”€â”€ Dockerfile                        # ğŸ’ª Docker image setup
â”‚
â”œâ”€â”€ LICENSE                           # ğŸ“š MIT License file
â”œâ”€â”€ main.py                           # ğŸš€ Entry point for training and predictions
â”œâ”€â”€ notebook/                         # ğŸ“š Jupyter notebooks
â”‚   â”œâ”€â”€ EDA & Feature_Engineering.ipynb        # ğŸ”„ Exploratory Data Analysis
â”‚   â”œâ”€â”€ Preprocessing & Model_training.ipynb   # ğŸ“ Model training steps
â”‚
â”œâ”€â”€ README.md                         # ğŸ“– Project documentation
â”œâ”€â”€ requirements.txt                  # ğŸ“Œ Dependencies for the project
â”œâ”€â”€ saved_models/                     # ğŸ¯ Production-ready models and transformers
â”œâ”€â”€ setup.py                          # âš™ï¸ Package setup for `src`
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/                   # ğŸ¢ Core pipeline components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py         # ğŸ“… Handles data collection
â”‚   â”‚   â”œâ”€â”€ data_transformation.py    # ğŸ”„ Prepares data for training
â”‚   â”‚   â”œâ”€â”€ data_validation.py        # âœ… Validates raw data
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py       # ğŸ“Š Evaluates the model
â”‚   â”‚   â”œâ”€â”€ model_pusher.py           # ğŸš€ Pushes the trained model to deployment
â”‚   â”‚   â”œâ”€â”€ model_training.py         # ğŸ“ Trains the machine learning model
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                     # âš™ï¸ Configuration management and environment variables
â”‚   â”œâ”€â”€ entity/                       # ğŸ“† Data structures for pipeline
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py        # ğŸ‚ Artifacts generated by pipeline stages
â”‚   â”‚   â””â”€â”€ config_entity.py          # âš™ï¸ Configuration-related entities
â”‚   â”‚
â”‚   â”œâ”€â”€ exceptions.py                 # â— Custom exception handling
â”‚   â”œâ”€â”€ logger.py                     # ğŸ’œ Logging setup
â”‚   â”œâ”€â”€ pipeline/                     # ğŸ”„ Pipeline automation
â”‚   â”‚   â”œâ”€â”€ clustering_pipeline.py    # ğŸ” Handles clustering predictions
â”‚   â”‚   â””â”€â”€ training_pipeline.py      # ğŸ¯ Automates training workflow
â”‚   â”‚
â”‚   â””â”€â”€ utils.py                      # ğŸ› ï¸ Utility functions
```

### ğŸ”„ EDA & Feature Engineering  
[![Completed EDA & FE](https://img.shields.io/badge/Completed-EDA%20%26%20FE-green)](notebooks/EDA%20&%20Feature_Engineering.ipynb)  
[![Completed Preprocessing & Model Training](https://img.shields.io/badge/Completed-Preprocessing%20%26%20Model%20Training-green)](notebooks/Preprocessing%20%26%20Model_training.ipynb)

### ğŸ”„ Machine Learning Pipelines  
[![Completed Training Pipeline](https://img.shields.io/badge/Completed-Training%20Pipeline-green)](src/pipeline/training_pipeline.py)  
[![Completed Clustering Prediction Pipeline](https://img.shields.io/badge/Completed-Cluster%20Pipeline-green)](src/pipeline/cluster_prediction_pipeline.py)

### ğŸ”„ Airflow DAGs  
[![Completed Airflow DAG](https://img.shields.io/badge/Completed-Airflow%20DAG-green)](airflow/dags)  
- [`training_pipeline.py`](airflow/dags/training_pipeline.py)  
- [`clustering_pipeline_dag.py`](airflow/dags/clustering_pipeline_dag.py)

---

## ğŸ“œ Architecture Documentation  
[![HLD (High-Level Design)](https://img.shields.io/badge/Ongoing-HLD-blue)](docs/HLD.pdf)  
[![LLD (Low-Level Design)](https://img.shields.io/badge/Ongoin-LLD-blue)](docs/LLD.pdf)  
[![DPR (Detailed Project Report)](https://img.shields.io/badge/Ongoin-DPR-blue)](docs/DPR.pdf)

---

## ğŸš€ Step-by-Step Deployment Guide  

### 1ï¸âƒ£ **AWS EC2 Instance Setup**  
ğŸ“Œ **Steps:**  
- Create an EC2 instance  
- Configure security groups  
- SSH into the instance  

  
**Install Docker:**
   SSH into your EC2 instance and run the following commands:

   ```bash
   curl -fsSL https://get.docker.com -o get-docker.sh
   sudo sh get-docker.sh
   sudo usermod -aG docker ubuntu
   newgrp docker
   docker --version
  ```

ğŸ“º **GIF Demo:**  
![EC2 Runner Activation](deployment/gifs/ec2_setup.gif)

> **GitHub Runner Setup(Example):**  
> After SSH-ing into your EC2 instance, set up the GitHub self-hosted runner by executing the following commands:

> ```bash
> # Create a directory for the GitHub Actions runner and navigate into it
> mkdir actions-runner && cd actions-runner
> 
> # Download the latest runner package (update the version as needed)
> curl -o actions-runner-linux-x64.tar.gz -L https://github.com/actions/runner/releases/download/v2.300.0/actions-runner-linux-x64-2.300.0.tar.gz
> 
> # Extract the runner package
> tar xzf actions-runner-linux-x64.tar.gz
> 
> # Configure the runner (replace <REPO_URL> and <RUNNER_TOKEN> with your repository URL and runner token)
> ./config.sh --url https://github.com/<your-username>/<your-repository> --token <RUNNER_TOKEN>
> 
> # Start the runner
> ./run.sh
> ```
>  
> *Note: Ensure you have generated a runner token from your GitHub repository's settings under "Actions" â†’ "Runners" â†’ create "New-self-hosted-runner" â†’ "linux".*

### 3ï¸âƒ£ **IAM Role & Access Key Setup**  
ğŸ“Œ **Steps:**  
- Create an IAM user  
- Attach necessary policies (e.g., `S3FullAccess`, `EC2FullAccess` . `AdministratorAcess`)  
- Generate `AWS_ACCESS_KEY_ID` & `AWS_SECRET_ACCESS_KEY` 

 ### 2ï¸âƒ£ **AWS S3 Bucket Creation**  
ğŸ“Œ **Steps:**  
- Navigate to AWS S3  
- Create a bucket  
- Set access permissions  

## ğŸ³ AWS ECR Creation Steps
### 1ï¸âƒ£ **Create ECR Repository**  
- Open the **Amazon ECR console** at https://console.aws.amazon.com/ecr.
- Select **Repositories** from the left menu and click on **Create repository**.
- Choose a **private repository** type and provide a **repository name** (e.g., `customer-personality-analysis`).
- Click **Create repository**.

### 4ï¸âƒ£ **GitHub Repository & Secrets Configuration**  
ğŸ“Œ **Steps:**  
- Create a GitHub repository  
- Navigate to `Settings` â†’ `Secrets and variables` â†’ `Actions`  
- Add the following secrets:  

  | Secret Name              | Description                      |
  |--------------------------|----------------------------------|
  | `AWS_ACCESS_KEY_ID`      | AWS Access Key                   |
  | `AWS_SECRET_ACCESS_KEY`  | AWS Secret Access Key            |
  | `AWS_REGION`             | AWS Region (e.g., `us-east-1`)     |
  | `BUCKET_NAME`            | S3 Bucket Name                   |
  | `MONGO_DB_URL`           | MongoDB Connection URL           |
  | `ECR_REPOSITORY_NAME`    | AWS ECR Repository Name          |
  | `AWS_ECR_LOGIN_URI`      | AWS ECR Login URI                |

ğŸ“º **GIF Demo:**  
![GitHub Secrets](deployment/gifs/github_secrets.gif)  

### 5ï¸âƒ£ **GitHub Actions CI/CD (`main.yml`)**  
ğŸ“Œ **Steps:**  
- Configure `.github/workflows/main.yml`  
- Automate deployment to AWS  

ğŸ“„ **GitHub Actions Workflow:**  
[![View GitHub Actions Workflow](https://img.shields.io/badge/View-Main.yml-blue?logo=github)](.github/workflows/main.yml)


